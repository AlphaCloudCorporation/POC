{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09e96faa-e52e-4c66-8804-e2b70fb6652f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark as ps\n",
    "import pandas as pd\n",
    "import pyspark.pandas as psd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\"spark.sql.ansi.enabled\", \"false\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "#Chargement\n",
    "df_data = psd.read_csv(\"/Volumes/alpha_cloud_ai_workspace/default/exp-data/cf_asset_fi_brut.csv\", sep=\";\")\n",
    "\n",
    "df_sink_fund = pd.read_csv(\"/Volumes/alpha_cloud_ai_workspace/default/exp-data/sinking_fund.csv\",\n",
    "                            sep=\";\",\n",
    "                            dtype={\"Cusip\": \"string\", \"timing\": np.int32, \"prop\": np.float32}\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1188fc40-3cb6-485c-b22b-b7d921c6f6dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_cash_flow_columns(df, num_cashflows=1200):\n",
    "    colones = dict()\n",
    "    for i in range(num_cashflows):\n",
    "        colones[f'cash_flow_{i+1}'] = 0\n",
    "    return df.reindex(columns=list(df.columns) + list(colones.keys()), fill_value=0.0)\n",
    "\n",
    "def add_pay_capital_columns(df, num_cashflows=1200):\n",
    "    colones = dict()\n",
    "    for i in range(num_cashflows):\n",
    "        colones[f'pay_capital_{i+1}'] = 0\n",
    "    return df.reindex(columns=list(df.columns) + list(colones.keys()), fill_value=0.0)\n",
    "\n",
    "def compute_notional_cul_with_amortisation(maturity, notionnel, paycap):\n",
    "    notional_cul = np.zeros(maturity + 1,dtype=float)\n",
    "    notional_cul[0] = notionnel\n",
    "\n",
    "    for i in range(maturity):\n",
    "        notional_cul[i+1] = notional_cul[i] - paycap[k]\n",
    "    return notional_cul\n",
    "\n",
    "def compute_notional_cul(maturity,notionnel):\n",
    "    notional_cul = np.zeros(maturity + 1,dtype=float)\n",
    "    notional_cul[0] = notionnel\n",
    "\n",
    "    for i in range(maturity):\n",
    "        notional_cul[i+1] = notional_cul[i]\n",
    "    return notional_cul\n",
    "\n",
    "def compute_projection_pay_capital(serie):\n",
    "    if serie[\"taux_flottant\"] == 0: #On ne projete pas les titres à taux flottant\n",
    "        if serie[\"cusip\"] in df_sink_fund['Cusip'].values:\n",
    "            amortization = df_sink_fund[df_sink_fund['Cusip'] == serie['cusip']]\n",
    "\n",
    "            for i in range(serie[\"maturity\"]):\n",
    "                if i in amortization['timing'].values:\n",
    "                    serie[f'pay_capital_{i+1}'] = amortization[amortization['timing'] == i]['prop'].values[0] * serie[\"notionnel\"]\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6701f7e-4409-4823-8dbc-89b07f50d592",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def projection_cf_assert_opt(data,sink_fund):\n",
    "    df_cash_flow = add_cash_flow_columns(data)\n",
    "    df_pay_capital = add_pay_capital_columns(data)\n",
    "\n",
    "    df_pay_capital = df_pay_capital.apply(compute_projection_pay_capital, axis=1)\n",
    "\n",
    "    return df_pay_capital\n",
    "\n",
    "result = projection_cf_assert_opt(df_data, df_sink_fund)\n",
    "result.to_csv(\"/Volumes/alpha_cloud_ai_workspace/default/exp-data/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c2c411f-c82c-43a3-8bb4-dda49264ec7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "  def projection_cf_asset(data, sink_fund):\n",
    "   \n",
    "    # Initialize the DataFrame\n",
    "    cfs = np.zeros((len(data), 1200))\n",
    "    pay_cap=np.zeros((len(data), 1200))\n",
    "    # Iterate over each row in the data\n",
    "    for j in range(len(data)):\n",
    "        if data.iloc[j]['taux_flottant'] == 0: #On ne projete pas les titres à taux flottant\n",
    "            tx_coupon = data.iloc[j]['coupon'] / data.iloc[j]['frequence']\n",
    "            maturity = data.iloc[j]['maturity']\n",
    "            # pay_cap = np.zeros(1200) #(maturity + 1) car on veut le cash flow de la dernière période\n",
    "            notionnel_cul = np.zeros(maturity + 1)\n",
    "            notionnel_cul[0] = data.iloc[j]['notionnel']\n",
    "           \n",
    "            for k in range(maturity):\n",
    "                if data.iloc[j]['cusip'] in sink_fund['Cusip'].values: # Si le titre à une cédule d'amortissement\n",
    "                    amortizer_cusip = sink_fund[sink_fund['Cusip'] == data.iloc[j]['cusip']]#\n",
    "                    if k in amortizer_cusip['timing'].values:\n",
    "                        pay_cap[j,k] = amortizer_cusip[amortizer_cusip['timing'] == k]['prop'].values[0] * data.iloc[j]['notionnel']\n",
    "                    notionnel_cul[k + 1] = notionnel_cul[k] - pay_cap[j,k]\n",
    "                    cfs[j, k] += pay_cap[j,k]\n",
    "                else:\n",
    "                    notionnel_cul[k + 1] = notionnel_cul[k]\n",
    "           \n",
    "            for i in range(data.iloc[j]['month_first_cf'], maturity + 1, int(12 / data.iloc[j]['frequence'])):\n",
    "                cfs[j, i - 1] += tx_coupon * notionnel_cul[i - 1]\n",
    "           \n",
    "            cfs[j, maturity - 1] += notionnel_cul[maturity]\n",
    "   \n",
    "    # Convert the NumPy array to a DataFrame\n",
    "    cfs_df = pd.DataFrame(cfs, columns=[f'Cash Flow {i}' for i in range(1, cfs.shape[1] + 1)])\n",
    "    cfs_pay_cap_df = pd.DataFrame(pay_cap, columns=[f'Pay Capital {i}' for i in range(1, pay_cap.shape[1] + 1)])\n",
    "    # Concatenate the data with the cash flows\n",
    "    result = pd.concat([data.reset_index(drop=True), cfs_df], axis=1)\n",
    "    results_cap = pd.concat([data.reset_index(drop=True), cfs_pay_cap_df], axis=1)\n",
    "    return result,results_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc24d2d7-abca-4e5c-8bca-6e7196ff8bc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result, result_cap= projection_cf_asset(df_asset, df_sinking)\n",
    "\n",
    "#display(result)\n",
    "display(result_cap)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark.pandas.2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
