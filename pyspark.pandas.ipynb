{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a39af91e-484e-4518-963c-42dd3e75f122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark as ps\n",
    "import pyspark.pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "#Configuration & Optimisation de l'engin Spark\n",
    "conf = SparkConf()\n",
    "#conf.set('spark.executor.memory', '2g')\n",
    "#conf.set('spark.driver.memory', '2g')\n",
    "\n",
    "#Pandas configurations\n",
    "#pd.options.display.max_rows = 5\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .master(\"local\")\n",
    "        .appName(\"TransformationExample\")\n",
    "        .config(\"spark.sql.ansi.enabled\", \"false\")\n",
    "        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "#Chargement\n",
    "df = pd.read_csv(\"/Volumes/alpha_cloud_ai_workspace/default/exp-data/cf_asset_mort_init.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "573fdb1a-c1dd-477c-9278-3362e0377df8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def add_cashflow_columns(df, num_cashflows=1200):\n",
    "        colones = dict()\n",
    "        for i in range(1200):\n",
    "            colones[f'cash_flow_{i+1}'] = 0\n",
    "        return df.reindex(columns=list(df.columns) + list(colones.keys()), fill_value=0.0)\n",
    "\n",
    "    def compute_notional_cul(versement, tx_interet, maturity, solde_capital):\n",
    "        notional_cul = np.zeros(maturity + 1,dtype=float)\n",
    "        notional_cul[0] = solde_capital\n",
    "\n",
    "        for i in range(maturity):\n",
    "            notional_cul[i+1] = notional_cul[i] - versement + notional_cul[i] * tx_interet \n",
    "        return notional_cul\n",
    "\n",
    "    def compute_cashflows(serie):\n",
    "        maturity = serie['maturity']\n",
    "        tx_interet = serie[\"taux_hyp\"] / serie[\"frequence\"]\n",
    "        notional_cul = compute_notional_cul(serie['versement'], tx_interet, maturity, serie['solde_capital'])\n",
    "\n",
    "        for i in range(maturity):\n",
    "            serie[f'cash_flow_{i+1}'] = serie['versement']\n",
    "            serie[f'cash_flow_{maturity}'] += notional_cul[maturity]     \n",
    "        return serie\n",
    "\n",
    "    def projection_cf_mortgage_opt(data):\n",
    "        df = add_cashflow_columns(data)\n",
    "        return df.apply(compute_cashflows, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3922c6ac-472a-4ca4-8c1a-993f8cd0edf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#25-06-30\n",
    "def projection_cf_mortgage(data):\n",
    "\n",
    "    # Initialize the DataFrame\n",
    "    cfs = np.zeros((len(data), 1200))\n",
    "\n",
    "    # Iterate over each row in the data\n",
    "    for j in range(len(data)):\n",
    "        if data.iloc[j]['maturity']>0:\n",
    "            tx_interet = data.iloc[j]['taux_hyp'] / data.iloc[j]['frequence']\n",
    "            maturity = data.iloc[j]['maturity']\n",
    "            pay_cap = data.iloc[j]['versement']\n",
    "            notionnel_cul = np.zeros(maturity + 1)\n",
    "            notionnel_cul[0] = data.iloc[j]['solde_capital']\n",
    "\n",
    "            for k in range(maturity):\n",
    "                notionnel_cul[k + 1] = notionnel_cul[k] - pay_cap + notionnel_cul[k]*tx_interet\n",
    "                cfs[j, k] += pay_cap\n",
    "\n",
    "            cfs[j, maturity - 1] += notionnel_cul[maturity]\n",
    "\n",
    "    # Convert the NumPy array to a DataFrame\n",
    "    cfs_df = pd.DataFrame(cfs, columns=[f'Cash Flow {i}' for i in range(1, cfs.shape[1] + 1)])\n",
    "\n",
    "    # Concatenate the data with the cash flows\n",
    "    result = pd.concat([data.reset_index(drop=True), cfs_df], axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ad18fcd-bdfd-4935-879c-ec53ecb161ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = projection_cf_mortgage(df)\n",
    "display(result)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark.pandas",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
