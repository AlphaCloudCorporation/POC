{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a39af91e-484e-4518-963c-42dd3e75f122",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1758297609693}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark as ps\n",
    "import pyspark.pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "#Configuration & Optimisation de l'engin Spark\n",
    "conf = SparkConf()\n",
    "#conf.set('spark.executor.memory', '2g')\n",
    "#conf.set('spark.driver.memory', '2g')\n",
    "\n",
    "#Pandas configurations\n",
    "#pd.options.display.max_rows = 5\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .master(\"local\")\n",
    "        .appName(\"TransformationExample\")\n",
    "        .config(\"spark.sql.ansi.enabled\", \"false\")\n",
    "        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "#Chargement\n",
    "df = pd.read_csv(\"/Volumes/alpha_cloud_ai_workspace/default/exp-data/cf_asset_mort_init.csv\", sep=\";\")\n",
    "\n",
    "#Ajout Interet\n",
    "df = df.assign(tx_interet = lambda x: x.taux_hyp / x.frequence)\n",
    "df = df.dropna()\n",
    "\n",
    "#Ajout des 1200 Cashflow\n",
    "colones = dict()\n",
    "for i in range(1200):\n",
    "    colones[f'cash_flow_{i+1}'] = 0\n",
    "df = df.reindex(columns=list(df.columns) + list(colones.keys()), fill_value=0.0)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d5d86a3-d12a-4241-b0d0-a4acfa8c1905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Operations\n",
    "def compute_cashflows(serie):\n",
    "    maturity = serie['maturity']\n",
    "    serie[f'cash_flow_1'] = serie['solde_capital']  # Initial cash flow\n",
    "\n",
    "    for i in range(1, maturity):\n",
    "        serie[f'cash_flow_{i+1}'] = serie[f'cash_flow_{i}'] - serie['versement'] + (serie[f'cash_flow_{i}'] * serie['tx_interet'])\n",
    "    return serie\n",
    "\n",
    "df = df.apply(compute_cashflows, axis='columns')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3922c6ac-472a-4ca4-8c1a-993f8cd0edf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#25-06-30\n",
    "def projection_cf_mortgage(data):\n",
    " \n",
    "    # Initialize the DataFrame\n",
    "    cfs = np.zeros((len(data), 1200))\n",
    "   \n",
    "    # Iterate over each row in the data\n",
    "    for j in range(len(data)):\n",
    "        if data.iloc[j]['maturity']>0:\n",
    "            tx_interet = data.iloc[j]['taux_hyp'] / data.iloc[j]['frequence']\n",
    "            maturity = data.iloc[j]['maturity']\n",
    "            pay_cap = data.iloc[j]['versement']\n",
    "            notionnel_cul = np.zeros(maturity + 1)\n",
    "            notionnel_cul[0] = data.iloc[j]['solde_capital']\n",
    "           \n",
    "            for k in range(maturity):\n",
    "                notionnel_cul[k + 1] = notionnel_cul[k] - pay_cap + notionnel_cul[k]*tx_interet\n",
    "                cfs[j, k] += pay_cap\n",
    " \n",
    "            cfs[j, maturity - 1] += notionnel_cul[maturity]\n",
    " \n",
    "    # Convert the NumPy array to a DataFrame\n",
    "    cfs_df = pd.DataFrame(cfs, columns=[f'Cash Flow {i}' for i in range(1, cfs.shape[1] + 1)])\n",
    "   \n",
    "    # Concatenate the data with the cash flows\n",
    "    result = pd.concat([data.reset_index(drop=True), cfs_df], axis=1)\n",
    "    return result\n",
    "\n",
    "df.info(verbose=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ad18fcd-bdfd-4935-879c-ec53ecb161ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = projection_cf_mortgage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4db7882a-f812-4c44-aa7d-588e402fe713",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.info(verbose=False)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark.pandas",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
