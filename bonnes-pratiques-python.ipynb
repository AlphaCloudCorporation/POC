{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4114bec0-be21-4676-9205-76141a5fef9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bonnes pratiques de programmation\n",
    "## Convention de nommage (Namming convention)\n",
    "Mettre en place une règle de nommage est essentiel pour assurer la lisibilité, la cohérence et la maintenabilité d'un projet, quel que soit son domaine (fichiers, programmation, cloud, réseaux, etc.). Sans une convention bien définie, les noms deviennent rapidement incohérents, difficiles à comprendre et sources d'erreurs.\n",
    "\n",
    "Nous proposons l'utilisation de la convention de nommage recommandé par le Python as travers la documentation PEP8, voici quelques exemples:\n",
    "- Class: Chaque mot commence par une majuscule tout les autre lettre sont en minuscules ex: DataLoader\n",
    "- Fonction: Tout en miniscule, un underscore sépare chaque mots ex: load_document\n",
    "- Constantes: Tout en majuscule, un underscore sépare chaque mots ex: MAX_VALUE\n",
    "- Variable: Tout en miniscule, un underscore sépare chaque mots ex: montant_total\n",
    "\n",
    "Vous n'avez pas a vous souciez d'apprendre ces règles par coeur, puisque l'assistant AI intégré peux le faire pour vous:\n",
    "- Selectionner la cellule ci-dessous\n",
    "- Activer l'assistant AI en mode Chat (Barre d'outil à droite, button en forme d'étoile).\n",
    "- Écrivez: Format using PEP8.\n",
    "- Si vous désirez des explications écrivez: Explain\n",
    "- Au besoins, apporter les modifications proposées.\n",
    "\n",
    "_ref: https://peps.python.org/pep-0008/#naming-conventions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1db92d2-f064-4be0-b7f4-3e1a35bf28f4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Convention de nommage"
    }
   },
   "outputs": [],
   "source": [
    "montant_epicerie = 100  # bon\n",
    "montantVehicule = 300  # Mauvais\n",
    "montant-taxes = 30  # Mauvais\n",
    "MontantTotal = 0  # Mauvais\n",
    "\n",
    "MontantTotal = montant_epicerie + montantVehicule + montant-taxes\n",
    "\n",
    "display(MontantTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "040c1c57-de7e-473d-a493-3ac31370b8ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Bonnes pratiques de programmation\n",
    "##Refactoring\n",
    "Le refactoring de code est une technique couramment utilisée en programmation informatique, et notamment pour le Data Engineering. Elle consiste à restructurer le code informatique sans modifier son comportement externe ou sa fonctionnalité.\n",
    "\n",
    "Dans le cadre d'un expérimentation avec notebook le refactoring va viser deux objectif:\n",
    "- Pendant l'expériementation:\n",
    "  - Organiser les cellules de façon à être plus efficient pendant l'experimentation.\n",
    "- Après l'expérimentation:\n",
    "  - Organiser le code afin qu'il soit plus lisible et plus facile à maintenir (utilisation de fonctions).\n",
    "\n",
    "Les étapes du réfactoring sont les suivantes:\n",
    "- On code l'experiementation et l'execute sans erreur pour une première fois.\n",
    "- On réorganise les cellules afin que les prochaines itérations de l'experiemention soient pous efficientes\n",
    "- On réorganise le code:\n",
    "  - Créer des fonctions pour alléger et réutiliser le code.\n",
    "  - On donne des nom significatifs aux variables et fonctions (rend le code facile a lire et plus compréhensible)\n",
    "- On execute l'experimentation à nouveau pour s'assurer que les changements n'ont pas altérer les résultats attendu.\n",
    "Voir les cellules ci-bas comme exemple complet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "778e9861-bc55-46a2-8be4-c189a09c3a7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Réfactoring - Étape 1\n",
    "On code l'experiementation et l'execute sans erreur pour une première fois.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f5e698e-7ef0-4222-a242-44b213ab0026",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Réfactoring - Étape 1"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark.pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dbfs:/databricks-datasets/nyctaxi/tripdata/fhv/fhv_tripdata_2015-01.csv.gz\")\n",
    "\n",
    "df[\"Year\"] = df[\"Pickup_date\"].dt.year\n",
    "df[\"Month\"] = df[\"Pickup_date\"].dt.month\n",
    "df[\"Day\"] = df[\"Pickup_date\"].dt.day\n",
    "df[\"Hour\"] = df[\"Pickup_date\"].dt.hour\n",
    "df = df.drop([\"locationID\",\"Pickup_date\"], axis=1)\n",
    "\n",
    "power = 2\n",
    "sum_of_hours = df[\"Hour\"].sum()\n",
    "nb_hours = len(df[\"Hour\"])\n",
    "mse = np.square(sum_of_hours / nb_hours)\n",
    "\n",
    "print(f\"Somme: {sum_of_hours}, Nb heures: {nb_hours}, MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "220c1460-a909-4375-b343-f18fedffa302",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Réfactoring - Étape 2\n",
    "On réorganise les cellules afin que les prochaines itérations de l'experiemention soient pous efficientes.\n",
    "- On met les libraries et le chargement du document dans une cellule\n",
    "- On met la transformations de données dans une autre cellule, cela permet de transformer de différentes façon les données sans avoir à recharger les données à chaque fois.\n",
    "- On met le calcul dans une cellule à part, ceci permet de modifier le calculs sans avoir à recharger les données et les transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c5c586c-0989-4197-b897-10d1f8ee9471",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Réfactoring - Étape 2.a"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark.pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dbfs:/databricks-datasets/nyctaxi/tripdata/fhv/fhv_tripdata_2015-01.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a30ee0fd-e03c-4f53-933c-9ea5026a3195",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Réfactoring - Étape 2.b"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Year\"] = df[\"Pickup_date\"].dt.year\n",
    "df[\"Month\"] = df[\"Pickup_date\"].dt.month\n",
    "df[\"Day\"] = df[\"Pickup_date\"].dt.day\n",
    "df[\"Hour\"] = df[\"Pickup_date\"].dt.hour\n",
    "df = df.drop([\"locationID\",\"Pickup_date\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94584d86-3367-4346-a708-e032189b2581",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Réfactoring - Étape 2.c"
    }
   },
   "outputs": [],
   "source": [
    "power = 2\n",
    "sum_of_hours = df[\"Hour\"].sum()\n",
    "nb_hours = len(df[\"Hour\"])\n",
    "mse = np.square(sum_of_hours / nb_hours)\n",
    "\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8700acca-37a9-4645-abe8-d41f0186eb0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Réfactoring - Étape 3\n",
    "On réorganise le code:\n",
    "- Créer des fonctions pour alléger et réutiliser le code.\n",
    "- On donne des nom significatifs aux variables et fonctions (rend le code facile a lire et plus compréhensible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93cfa45b-bad8-47e2-bd32-aa9943a4b72c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Réfactoring - Étape 3.a"
    }
   },
   "outputs": [],
   "source": [
    "def chargement_donnes(fichier):\n",
    "    repertoire = \"dbfs:/databricks-datasets/nyctaxi/tripdata/fhv/\"\n",
    "    url = repertoire + fichier\n",
    "    return pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0196e7e8-7c94-438f-9a8d-d6b2c4d126a9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Réfactoring - Étape 3.b"
    }
   },
   "outputs": [],
   "source": [
    "def transformations_donnees(df):\n",
    "    df[\"Year\"] = df[\"Pickup_date\"].dt.year\n",
    "    df[\"Month\"] = df[\"Pickup_date\"].dt.month\n",
    "    df[\"Day\"] = df[\"Pickup_date\"].dt.day\n",
    "    df[\"Hour\"] = df[\"Pickup_date\"].dt.hour\n",
    "    return df.drop([\"locationID\",\"Pickup_date\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1178dc95-af80-467f-9c20-1a5b425df18e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Réfactoring - Étape 3.c"
    }
   },
   "outputs": [],
   "source": [
    "def calculer_mse(df):\n",
    "    power = 2\n",
    "    somme_heures = df[\"Hour\"].sum()\n",
    "    nb_heures = len(df[\"Hour\"])\n",
    "    mse = np.square(somme_heures / nb_heures)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e80e693-47a5-4c65-bad9-a588e15d2620",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Réfactoring - Étape 4\n",
    "On execute l'experimentation à nouveau pour s'assurer que les changements n'ont pas altérer les résultats attendu. Voir les cellules ci-bas comme exemple complet.\n",
    "\n",
    "Vous pouvez constatez dans la cellule ci-bas a quel point le code est plus lisible et facile a comprendre apres le refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8a78c11-0d05-4df4-9dfc-8d386470d945",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Réfactoring - Étape 4"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark.pandas as pd\n",
    "\n",
    "fichier = \"fhv_tripdata_2015-01.csv.gz\"\n",
    "\n",
    "df = chargement_donnes(fichier)\n",
    "df = transformations_donnees(df)\n",
    "mse = calculer_mse(df)\n",
    "\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bonnes-pratiques-python",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
