{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bf0546d-506a-4ae6-a569-eabe58a2205b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Comment réduire la durée du traitement\n",
    "Il existe plusieurs techniques et méthodes pour réduire la durée du traitement.\n",
    "Voici les principales:\n",
    "- Nettoyer le jeux de données (data cleaning).\n",
    "- Utiliser une librairie de traitement de données qui est optimisée pour le traitement parallèle (pandas vs pyspark).\n",
    "- Utiliser un cluster plus puissant ou mieux adapter au type de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19429c89-577b-4237-84f0-751d58b9b2e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Nettoyer le jeux de données\n",
    "Le but du nettoyage de données et d'éliminer d'entrer de jeux, les données qui ne seront pas utilisé dans le cadre du calcul actuariel.\n",
    "Ceci va permettre entre autre de diminuer le temps de chargement.\n",
    "\n",
    "Pour l'exemple ci-dessous nous ramenons l'ensemble des colones (59 colones en tout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc21e29a-0c71-49a9-acd7-7b51e4cf0f9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.pandas as pd\n",
    "\n",
    "path = \"dbfs:/databricks-datasets/data.gov/farmers_markets_geographic_data/data-001/market_data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(f\"Nombre de colones {df.columns.size}\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8be3ae9-8029-4b87-bb07-515a2a612a94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Faisons le même chargement, mais cette fois ci avec seulement les colones nescessaires (FMID,MarketName, Zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ef17a8c-4359-4e33-9a6d-31c7e0ea55d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.pandas as pd\n",
    "\n",
    "path = \"dbfs:/databricks-datasets/data.gov/farmers_markets_geographic_data/data-001/market_data.csv\"\n",
    "df = pd.read_csv(path,usecols=['FMID','MarketName','zip'])\n",
    "\n",
    "print(f\"Nombre de colones {df.columns.size}\")\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "comment-optimiser-le-traitement",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
